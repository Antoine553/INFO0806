---
title: "INFO0806 – Statistiques appliquées"
author: "FUZELLIER Maxence, BARBET Antoine"
date: "`r format(Sys.time(), '%d %B, %Y')`"
language: R
cran: http://cran.rstudio.com
output: 
  html_document:
    toc: true # table of content true
    toc_depth: 3 # three depths of headings (#, ## and ###)
editor_options: 
  chunk_output_type: inline
---

<style>
body {
  text-align: justify;
  font-size: 14pt;
}
</style>

<body>

******

<center>
**↓↓ Accès au projet ↓↓**
<br />
[Lien GitHub du projet](https://github.com/Antoine553/INFO0806)
</center>

******

<br />
# **Introduction**

<br />

Dans le cadre du module de statistiques appliquées, nous avions abordé les bases des statistiques et pris en main des outils permettant d'effectuer des operation statistique avancée grâce au langage R, à partir d’un jeu de données. Ainsi, notre choix s'est porté sur des données statistiques relatives à <bold>je sais pas</bold>. Celles-ci proviennent du site internet <bold>je sais pas</bold>.

Ce projet de statistiques appliquées consiste en l'utilisation d'outils R adaptés afin d'effectuer des régression linéaire sur notre jeu de données et produire un rapport.
<br />

******

<br />
# **Outils et environnement de travail**


## R et RStudio 
 
R est un langage de programmation dont le but est de pouvoir traiter et organiser des jeux de données afin de pouvoir y appliquer des tests statistiques plus ou moins complexes et se représenter ces données graphiquement à l'aide d'une grande variété de graphiques disponibles. RStudio est une application proposant un environnement de développement et des outils adaptés au langage et à l'environnement de programmation R. 

La fonction principale de RStudio consiste à faciliter le développement d'applications en langage R. Pour ce faire, le programme dispose de nombreux outils qui vous permettent notamment de créer des scripts, compiler du code, créer des graphes, ainsi que de travailler avec divers jeux de données. 

<br />

## R markdown

L’extension R markdown permet de générer des documents de manière dynamique en mélangeant texte mis en forme et résultats produits par du code R. Les documents générés peuvent être au format HTML, PDF, Word, et bien d’autres. C’est donc un outil très pratique pour l’exportation, la communication et la diffusion de résultats d’analyse.

<br />

## Outils complémentaires 

* *tidyverse* : Il s’agit d’une collection d’extensions relatives à la science des données, et permettant la manipulation des tableaux de données, l’import/export de données, la manipulation de variables ou, entre autres, la visualisation de données ;
* *data.table* : Extension et manipulation avancée des tableaux de données ;
* *plotly* et *highcharter* : Comme *ggplot2* (compris dans le *tidyverse*), ces packages permettent la visualisation de données, à la différence près qu’ils rendent ces graphiques interactifs ;
* *hrbrthemes* : Thèmes pour *ggplot2*.

<br />
<br />

******

<br />

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r load, message=FALSE, warning=FALSE, include=FALSE}
install.packages("GGally", repo="http://cran.rstudio.com/")

library(data.table)
library(tidyverse)
library(hrbrthemes)
library(plotly)
library(ggplot2)
library(GGally)
library(car)
```

# **Données**

Chargement des jeux de données :

notre jeu de donnée se compose de 102 observations avec 6 variables. Les variables sont :

éducation: nombre moyen d'années d'études des titulaires de profession.
revenu: Le revenu moyen des titulaires de profession, en dollars.
femmes: pourcentage de femmes dans la profession.
prestige: La cote de prestige moyenne pour la profession.
recensement: Le code de la profession utilisé dans l'enquête.
type: Professionnel et gestionnaire (prof), col blanc (wc), col bleu (bc) ou manquant (NA) (Fox et Weisberg 2011)

```{r datasets, message=FALSE}
data <- read_csv("data/prestige.csv") %>% as_tibble()
data
```
<br />

# **Régression linéaire**

En statistiques, et en apprentissage automatique, un modèle de régression linéaire est un modèle de régression qui cherche à établir une relation linéaire entre une variable, dite expliquée, et une ou plusieurs variables, dites explicatives.

Dans un premier temps nous pouvons etudier rapidement d'eventuel corrélation entre deux variables à l'aide d'un scatterplot. Ici nous utilisons la fonction scatterplotMatrix afin de pouvoir en observer plusieur en même temps.
```{r , message=FALSE}
generate_plot <- function(data, mapping){
    ggplot(data = data, mapping = mapping) + 
        geom_point() + 
        geom_smooth(method=loess, fill="red", color="red") +
        geom_smooth(method=lm, fill="blue", color="blue")
}

ggpairs(data,columns = 1:4, lower = list(continuous = generate_plot))

```

Avec les observation précdante nous pouvons déjà écarter certaine linéarité et choisir lesquelles sont interressantes à étudier. Ici, nous reprenons donc la relation entre la variable prestige (il s’agit d’un score de prestige relatif à la profession) et la variable éducation (qui reflète le niveau d’étude). Cette fois nous utilison ggplot pour une meilleur visualisation et la possibilité d'interagig avec notre graphique.

```{r education}
education <- data %>% 
  ggplot(aes(x = education, y = prestige)) +
  geom_point() +
  geom_smooth(method = loess, color = "red", fill = "#69b3a2", se = T) +
  geom_smooth(method = lm, color = "blue", se = F) +
  theme_ipsum()

scatter_edu <- ggplotly(education)
scatter_edu
```
La ligne en trait plein est la droite de régression linéaire (définie par la méthode des moindres carrés) entre les deux variables. La ligne centrale en pointillé est la courbe de régression locale de type lowess.
Elle indique la tendance globale entre les deux variables. Les deux lignes extérieures représentent un intervalle de confiance de la courbe lowess.

On peut voir que que la droite de régression est presque toujours comprise dans l’intervalle de confiance de la courbe lowess. la linéarité de ces variables est donc très probable.

<br />
Nous testons aussi la relation entre la variable prestige et la variable income.

```{r income}
income <- data %>% 
  ggplot(aes(x = income, y = prestige)) +
  geom_point() +
  geom_smooth(method = loess, color = "red", fill = "#69b3a2", se = T) +
  geom_smooth(method = lm, color = "blue", se = F) +
  theme_ipsum()

scatter_inc <- ggplotly(income)
scatter_inc
```

Ici, en regardant la forme du lien entre la variable prestige et la variable income, on s’aperçoit que la droite de régression suis bien moin l’intervalle de confiance de la courbe lowess. l’hypothèse de linéarité est alors plus critiquable.

```{r}
prest.lm1 <- lm(prestige~education, data = Prestige)
prest.lm1
```

```{r lagplot}
bacf <- acf(residuals(prest.lm1), plot = F)
bacfdf <- with(bacf, data.frame(lag, acf))
conf.level <- 0.95
ciline <- qnorm((1 - conf.level)/2)/sqrt(length(residuals(prest.lm1)))

lag_plot <- bacfdf %>%
  ggplot(aes(x = lag, y = acf)) +
  geom_hline(aes(yintercept = 0)) +
  geom_segment(aes(xend = lag, yend = 0)) +
  geom_hline(aes(yintercept = ciline), linetype = 3, color = 'darkblue') +     
  geom_hline(aes(yintercept = -ciline), linetype = 3, color = 'darkblue') +
  theme_ipsum()

lag_plot <- ggplotly(lag_plot, tooltip = c("lag", "acf"))
lag_plot
```


```{r durbinWatson_edu}
durbinWatsonTest(prest.lm1)
```

```{r qq_edu}
qq_edu <- prest.lm1 %>%
  ggplot(aes(sample = residuals(prest.lm1) / 10))+
  stat_qq() + stat_qq_line() +
  #theme_ipsum() +
  labs(x = "Theoretical Quantiles\nlm(prestige ~ education)", 
       y = "Standardized residuals")

#qq_edu <- ggplotly(qq_edu)
qq_edu
```

```{r shapiro_edu}
shapiro.test(residuals(prest.lm1))
```

```{r}
prest.lm2 <- lm(prestige~income, data = Prestige)
prest.lm2
```

```{r qq_inc}
qq_inc <- prest.lm2 %>%
  ggplot(aes(sample = residuals(prest.lm2) / 10))+
  stat_qq() + stat_qq_line() +
  #theme_ipsum() +
  labs(x = "Theoretical Quantiles\nlm(prestige ~ income)", 
       y = "Standardized residuals")

#qq_inc <- ggplotly(qq_inc)
qq_inc
```


```{r shapiro_inc}
shapiro.test(residuals(prest.lm2))
```

```{r}
plot(prest.lm1, 3)
```

```{r}
ncvTest(prest.lm1)
```

```{r}
plot(prest.lm1,1)
```

```{r}
summary(prest.lm1)
```

```{r}
confint(prest.lm1)
```

```{r}
influenceIndexPlot(prest.lm1)
```

```{r}
outlierTest(prest.lm1)
```

```{r}
prest.lm1bis <- lm(prestige~education, data=Prestige[-c(53,67),])
compareCoefs(prest.lm1 ,prest.lm1bis) 
```

```{r}
my_df <- data.frame(education=c(10.25))
predict(prest.lm1, newdata=my_df)
```

```{r}
predict(prest.lm1, newdata=my_df, interval="prediction")
predict(prest.lm1, newdata=my_df, interval="confidence")
```

```{r}
my_df <- data.frame(education=c(10.25, 11.25, 12.25))
predict(prest.lm1, newdata=my_df,interval="confidence")
```

```{r}
my_pres <- Prestige
my_pres$res <-residuals(prest.lm1)
head(my_pres)
```

```{r}
my_pres$fitted <-fitted(prest.lm1)
head(my_pres)
```

```{r}
head(predict(prest.lm1))
head(fitted(prest.lm1))
```

```{r}
vcov(prest.lm1)
```

```{r}
ggplot(Prestige, aes(y=prestige, x=education))+
  geom_point()+
  geom_smooth(colour="red", method="lm", fill="red") +
  ylab("Prestige")+
  xlab("education") +
  theme_classic()+
  annotate("text", x = 9, y = 80, label = "prestige = -10.73 + 5.36 * education\n (pval<0.001)")
```

```{r}
int_pred <- predict(prest.lm1, interval="prediction")
my_prest2 <-cbind(Prestige, int_pred)
head(my_prest2)
```

```{r}
ggplot(my_prest2, aes(y=prestige, x=education))+
  geom_point()+
  geom_smooth(colour="red", method="lm", fill="red") +
  geom_line(aes(y=lwr), color = "red", linetype = "dashed")+
  geom_line(aes(y=upr), color = "red", linetype = "dashed")+    
  ylab("Prestige")+
  xlab("education") +
  theme_classic()+
  annotate("text", x = 9, y = 80, label = "prestige = -10.73 + 5.36 * education\n (pval<0.001)")
```


</body>